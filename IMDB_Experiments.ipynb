{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Team Formation framework with IMDB datasets\n",
    "## Balancing Task Coverage vs. Maximum Expert Load\n",
    "## Karan Vombatkere, Spring 2022\n",
    "\n",
    "#Imports\n",
    "import json, time\n",
    "import TeamFormationProblem as TFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import IMDB Data\n",
    "def importIMDBData(experts_filename, tasks_filename):\n",
    "    with open(experts_filename, 'r') as f:\n",
    "        expert_skills_list = json.loads(f.read())\n",
    "    \n",
    "    with open(tasks_filename, 'r') as f:\n",
    "        task_skills_list = json.loads(f.read())\n",
    "\n",
    "    print(\"Imported IMDB dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run for specific IMDB Dataset year\n",
    "imdb_data_path = 'datasets/imdb/'\n",
    "y = 2015\n",
    "experts_file = imdb_data_path + 'imdb_experts_' + str(y) + '.txt'\n",
    "tasks_file = imdb_data_path + 'imdb_tasks_' + str(y) + '.txt'\n",
    "print(\"IMDB Dataset: {}, {}\".format('imdb_experts_' + str(y), 'imdb_tasks_' + str(y)))\n",
    "\n",
    "imdb_tasks, imdb_experts = importIMDBData(experts_file, tasks_file)\n",
    "IMDBTest = TFP.TeamFormationProblem(imdb_tasks, imdb_experts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDict, F_vals, workLoad_vals = IMDBTest.computeTaskAssigment(algorithms=['random', 'no_update_greedy', 'task_greedy'], lambdaVal=0.1)\n",
    "#runtimeDict, F_vals, workLoad_vals = IMDBTest.computeTaskAssigment(algorithms=['no_update_greedy'], lambdaVal=0.1)244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Run algorithm on IMDB datasets\n",
    "def testIMDBDatasets(write_flag, algoList):\n",
    "    imdb_data_path = 'datasets/imdb/'\n",
    "    movieYears = [2015, 2018, 2020]\n",
    "\n",
    "    if write_flag:\n",
    "        runTimeStamp = str(time.strftime(\"%m-%d-%H:%M:%S\", time.localtime(time.time())))\n",
    "        imdb_outfilename = \"experiments/imdb_\" + runTimeStamp + \".txt\"\n",
    "        outfile_imdb = open(imdb_outfilename, \"a\")\n",
    "        outfile_imdb.write(\"IMDB dataset Team-Formation Algorithms: {}\\n\".format(runTimeStamp))\n",
    "\n",
    "    for y in movieYears:\n",
    "        experts_file = imdb_data_path + 'imdb_experts_' + str(y) + '.txt'\n",
    "        tasks_file = imdb_data_path + 'imdb_tasks_' + str(y) + '.txt'\n",
    "        print(\"IMDB Dataset: {}, {}\".format('imdb_experts_' + str(y), 'imdb_tasks_' + str(y)))\n",
    "\n",
    "        imdb_tasks, imdb_experts = importIMDBData(experts_file, tasks_file)\n",
    "        IMDBTest = TFP.TeamFormationProblem(imdb_tasks[0:600], imdb_experts[0:100])\n",
    "\n",
    "        rt_dict, f_dict, workload_dict, coverageList = IMDBTest.computeTaskAssigment(algorithms=algoList, plot_flag=False)\n",
    "        coverageListString = \"\"\n",
    "        for c_i in coverageList:\n",
    "            c_i_str = \", \"+str(np.round(c_i, 2))\n",
    "            coverageListString += c_i_str\n",
    "        print(coverageListString)\n",
    "        #Write output to file\n",
    "        if write_flag:\n",
    "            runInfo = \"\\nIMDB movieYear = {}, Experts = {}, Tasks = {}\".format(str(y), str(IMDBTest.n), str(IMDBTest.m))\n",
    "            outfile_imdb.write(runInfo)\n",
    "\n",
    "            f_info = \"\\nAlgorithm Objectives (F_max): Lazy Greedy = {}; No-Update-Greedy = {}; Task Greedy = {}; Random = {};\\\n",
    "                \".format(f_dict['lazyGreedy'], f_dict['noUpdateGreedy'], f_dict['taskGreedy'], f_dict['random'])\n",
    "            outfile_imdb.write(f_info)   \n",
    "\n",
    "            wload_info = \"\\nAlgorithm optimal workloads: Lazy Greedy = {}; No-Update-Greedy = {}; Task Greedy = {}; Random = {};\\\n",
    "                \".format(workload_dict['lazyGreedy'], workload_dict['noUpdateGreedy'], workload_dict['taskGreedy'], workload_dict['random'])\n",
    "            outfile_imdb.write(wload_info)   \n",
    "\n",
    "            runtimeInfo = \"\\nAlgorithm Runtimes: Total = {:.3f}s; Lazy Greedy = {:.3f}s; No-Update-Greedy = {:.3f}s; Task Greedy = {:.3f}s; Random = {:.3f}s;\\\n",
    "                \\n\".format(rt_dict['total'], rt_dict['lazyGreedy'], rt_dict['noUpdateGreedy'], rt_dict['taskGreedy'], rt_dict['random'])\n",
    "            outfile_imdb.write(runtimeInfo)\n",
    "\n",
    "            outfile_imdb.write(\"\\nCoverage List: {}\".format(coverageListString))\n",
    "\n",
    "    \n",
    "    if write_flag:\n",
    "        outfile_imdb.close()\n",
    "\n",
    "    return None\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
