{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Team Formation framework with real datasets\n",
    "## Balancing Task Coverage vs. Maximum Expert Load\n",
    "## Karan Vombatkere, Spring 2022\n",
    "\n",
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json, time\n",
    "import TeamFormationProblem as TFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freelancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Freelancer data\n",
    "#Freelancer from DropBox link: https://www.dropbox.com/sh/8zpsi1etvvvvj5k/AAD-J9ZQmSsbnSmEILBMD9uxa/datasets/real?dl=0&subfolder_nav_tracking=1\n",
    "#freelance_experts.csv and freelance_projects.csv\n",
    "\n",
    "def extract_skills(row):\n",
    "    skills = []\n",
    "    for i,val in enumerate(row):\n",
    "        if val == 1:\n",
    "            skills.append(str(i))\n",
    "    return skills            \n",
    "\n",
    "    \n",
    "def importFreelancerData(experts_filename='datasets/freelancer/freelancer_experts.csv', tasks_filename='datasets/freelancer/freelancer_projects.csv'):\n",
    "    #Extract tasks skills as list\n",
    "    freelance_tasks_df = pd.read_csv(tasks_filename, header=None)\n",
    "    print(\"Freelancer tasks df shape: \", freelance_tasks_df.shape)\n",
    "    freelance_tasks_df['Task_Skills'] = freelance_tasks_df.apply(lambda row: extract_skills(row), axis=1)\n",
    "    task_skills_list = freelance_tasks_df.Task_Skills.to_list()\n",
    "    \n",
    "    #Extract experts skills as list\n",
    "    freelance_experts_df = pd.read_csv(experts_filename, header=None)\n",
    "    print(\"Freelancer experts df shape: \", freelance_experts_df.shape)\n",
    "    freelance_experts_df['Expert_Skills'] = freelance_experts_df.apply(lambda row: extract_skills(row), axis=1)\n",
    "    expert_skills_list = freelance_experts_df.Expert_Skills.to_list()\n",
    "\n",
    "    print(\"Imported Freelancer dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freelancer tasks df shape:  (992, 175)\n",
      "Freelancer experts df shape:  (1212, 175)\n",
      "Imported Freelancer dataset. Num Experts=1212, Num Tasks=992\n"
     ]
    }
   ],
   "source": [
    "t,e = importFreelancerData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createExpertTaskSkillMatrices(expert_skills_list, task_skills_list):\n",
    "    '''\n",
    "    Create (n_experts, n_skills) and (m_tasks, n_skills) matrices from skill and expert lists\n",
    "    ARGS:\n",
    "        expert_skills_list : List of lists of expert skill indices as stored in dataset txt files\n",
    "        task_skills_list   : List of lists of task skill indices as stored in dataset txt files\n",
    "    RETURN:\n",
    "        experts_mat : (n_experts, n_skills) binary matrix\n",
    "        tasks_mat   : (m_tasks, n_skills) binary matrix\n",
    "        tasks_not_coverable : list of tasks that are not fully coverable\n",
    "    '''\n",
    "    #First check if all tasks are coverable and get set of all skills\n",
    "    all_experts_skillset = set()\n",
    "\n",
    "    for expert_i in expert_skills_list:\n",
    "        for skill in expert_i:\n",
    "            all_experts_skillset = all_experts_skillset.union({skill})\n",
    "\n",
    "    s_skills = len(all_experts_skillset) #Get total number of skills\n",
    "\n",
    "    #Create (n_experts, n_skills) matrix\n",
    "    experts_mat = np.zeros((len(expert_skills_list), s_skills), dtype=np.int8)\n",
    "    for expert_index, expert_i in enumerate(expert_skills_list):\n",
    "        for skill in expert_i:\n",
    "            skill_index = int(skill)\n",
    "            experts_mat[expert_index][skill_index] = 1\n",
    "\n",
    "    print(\"Generated expert-skill matrix, shape = {}\".format(experts_mat.shape))\n",
    "    \n",
    "    #Create (m_tasks, n_skills) matrix\n",
    "    tasks_mat = np.zeros((len(task_skills_list), s_skills), dtype=np.int8)\n",
    "\n",
    "    tasks_not_coverable = []\n",
    "    allTasksCoverable = True\n",
    "\n",
    "    for task_index, task_i in enumerate(task_skills_list):\n",
    "        for skill in task_i:\n",
    "            skill_index = int(skill)\n",
    "            tasks_mat[task_index][skill_index] = 1\n",
    "\n",
    "            if skill not in all_experts_skillset:\n",
    "                allTasksCoverable = False\n",
    "                tasks_not_coverable.append(task_index)\n",
    "    \n",
    "    print(\"Generated task-skill matrix, shape = {}\".format(tasks_mat.shape))\n",
    "\n",
    "    if not allTasksCoverable:\n",
    "        print(\"{} Tasks not fully coverable: {}\".format(len(tasks_not_coverable), tasks_not_coverable))\n",
    "    \n",
    "    return experts_mat, tasks_mat, tasks_not_coverable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLPSolutionToMatrix(lp_model, n, m):\n",
    "    '''\n",
    "    Convert the lp_model output to a (n_experts x m_tasks) matrix\n",
    "    Entries in n x m matrix represent probabilities of assigning expert i to task j\n",
    "    ARGS:\n",
    "        lp_model: Gurobi solved LP model\n",
    "        n       : number of experts\n",
    "        m       : number of tasks\n",
    "    RETURN:\n",
    "        LP_soln_matrix: (n_experts x m_tasks) matrix with LP solution X_ji values as per Power in Unity paper\n",
    "    '''\n",
    "    v = lp_model.getVars()\n",
    "    count = 0\n",
    "\n",
    "    LP_soln_matrix = np.zeros((n, m), dtype=np.float32)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            LP_soln_matrix[i][j] = v[count].x\n",
    "            count += 1\n",
    "\n",
    "    return LP_soln_matrix\n",
    "\n",
    "\n",
    "def solve_LP(expertMatrix, taskMatrix):\n",
    "    '''\n",
    "    Given (n_experts, n_skills) and (m_tasks, n_skills) matrices, solve the relaxed ILP and return \n",
    "    a (n_experts x m_tasks) matrix with LP solution\n",
    "    ARGS:\n",
    "        expertMatrix : (n_experts, n_skills) binary matrix of expert skills\n",
    "        taskMatrix   : (m_tasks, n_skills) binary matrix of task skills\n",
    "    RETURN:\n",
    "        LP_solution_matrix: (n_experts x m_tasks) matrix with LP solution X_ji values as per Power in Unity paper\n",
    "    '''\n",
    "    #Create empty assignment matrix of shape (n_experts x m_tasks)\n",
    "    X =  np.zeros((len(expertMatrix), len(taskMatrix)), dtype=np.int8)\n",
    "\n",
    "    #Create Gurobi LP Model\n",
    "    m = gp.Model(\"TaskCoverageLP\")\n",
    "\n",
    "    #Add variables\n",
    "    x = m.addVars(len(X), len(X[1]), vtype='S', ub=1.0, name=\"x\")\n",
    "\n",
    "    #Set objective function\n",
    "    L = m.addVar(vtype='S', name = 'Load')\n",
    "    obj = 1*L\n",
    "    m.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "    #Add constraints\n",
    "    # c1 - Load of each expert is upper bounded by L\n",
    "    c1 = m.addConstrs(x.sum(i,'*') <= L for i in range(len(X)))\n",
    "\n",
    "    # c2 - Each task is (fully) covered\n",
    "    experts_transpose = np.transpose(expertMatrix)\n",
    "    c2 = m.addConstrs(gp.quicksum(experts_transpose[j][l]*x[l,i] for l in range(len(expertMatrix))) >= taskMatrix[i][j] \n",
    "                                        for i in range(len(taskMatrix)) for j in range(len(taskMatrix[0])) if taskMatrix[i][j] > 0)\n",
    "        \n",
    "    # Silence model output\n",
    "    # m.setParam('OutputFlag', 0)\n",
    "\n",
    "    #Solve LP model\n",
    "    m.optimize()\n",
    "\n",
    "    LP_solution_matrix = convertLPSolutionToMatrix(m, len(expertMatrix), len(taskMatrix))\n",
    "\n",
    "    return LP_solution_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated expert-skill matrix, shape = (992, 175)\n",
      "Generated task-skill matrix, shape = (1212, 175)\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (mac64[rosetta2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:04,786 |INFO: Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (mac64[rosetta2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:04,787 |INFO: Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimize a model with 2758 rows, 1202305 columns and 1348690 nonzeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:04,787 |INFO: Optimize a model with 2758 rows, 1202305 columns and 1348690 nonzeros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fingerprint: 0xc9620a3c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:04,798 |INFO: Model fingerprint: 0xc9620a3c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable types: 0 continuous, 0 integer (0 binary)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:04,801 |INFO: Variable types: 0 continuous, 0 integer (0 binary)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semi-Variable types: 1202305 continuous, 0 integer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:04,802 |INFO: Semi-Variable types: 1202305 continuous, 0 integer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient statistics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:04,808 |INFO: Coefficient statistics:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Matrix range     [1e+00, 1e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:04,809 |INFO:   Matrix range     [1e+00, 1e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Objective range  [1e+00, 1e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:04,809 |INFO:   Objective range  [1e+00, 1e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Bounds range     [1e+00, 1e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:04,810 |INFO:   Bounds range     [1e+00, 1e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RHS range        [1e+00, 1e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:04,811 |INFO:   RHS range        [1e+00, 1e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presolve removed 2300 rows and 1194064 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,253 |INFO: Presolve removed 2300 rows and 1194064 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presolve time: 1.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,253 |INFO: Presolve time: 1.39s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presolved: 458 rows, 8241 columns, 18111 nonzeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,257 |INFO: Presolved: 458 rows, 8241 columns, 18111 nonzeros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable types: 8241 continuous, 0 integer (0 binary)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,259 |INFO: Variable types: 8241 continuous, 0 integer (0 binary)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,263 |INFO: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root relaxation: objective 6.000000e+00, 175 iterations, 0.00 seconds (0.00 work units)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,263 |INFO: Root relaxation: objective 6.000000e+00, 175 iterations, 0.00 seconds (0.00 work units)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,518 |INFO: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,519 |INFO:     Nodes    |    Current Node    |     Objective Bounds      |     Work\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,519 |INFO:  Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,520 |INFO: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*    0     0               0       6.0000000    6.00000  0.00%     -    1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,521 |INFO: *    0     0               0       6.0000000    6.00000  0.00%     -    1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,804 |INFO: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explored 1 nodes (175 simplex iterations) in 2.02 seconds (2.81 work units)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,805 |INFO: Explored 1 nodes (175 simplex iterations) in 2.02 seconds (2.81 work units)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread count was 8 (of 8 available processors)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,805 |INFO: Thread count was 8 (of 8 available processors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,806 |INFO: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution count 1: 6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,806 |INFO: Solution count 1: 6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,807 |INFO: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal solution found (tolerance 1.00e-04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,808 |INFO: Optimal solution found (tolerance 1.00e-04)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best objective 6.000000000000e+00, best bound 6.000000000000e+00, gap 0.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 17:16:06,816 |INFO: Best objective 6.000000000000e+00, best bound 6.000000000000e+00, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "expertMatrix, taskMatrix, tnc = createExpertTaskSkillMatrices(t,e)\n",
    "LP_sol = solve_LP(expertMatrix, taskMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setCoverLP():\n",
    "    '''\n",
    "    Adapted LP algorithm for the non-online setting of the Load minimization problem by Anagnostopoulos et al.\n",
    "    ARGS:\n",
    "        LP_solution : (n_experts x m_tasks) matrix with LP solution X_ji values \n",
    "    RETURN:\n",
    "        task_assignment\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cost is (objective value): %g' % obj.getValue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numVars = 0\n",
    "for v in m.getVars():\n",
    "    if v.X > 0:\n",
    "        numVars += 1\n",
    "        print('%s %g' % (v.VarName, v.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLPSolnMatrix(lp_model, n, m):\n",
    "    v = lp_model.getVars()\n",
    "    count = 0\n",
    "\n",
    "    LP_soln_matrix = np.zeros((n, m), dtype=np.int8)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            LP_soln_matrix[i][j] = v[count].x\n",
    "            count += 1\n",
    "\n",
    "    return LP_soln_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,e = importFreelancerData()\n",
    "FreelancerTest = TFP.TeamFormationProblem(t, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDict, F_vals, workLoad_vals = FreelancerTest.computeTaskAssigment(algorithms=['lazy_greedy', 'random', 'no_update_greedy','task_greedy'], lambdaVal=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freelancerCovList = FreelancerTest.getCoverageValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guru Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guru Dataset\n",
    "def extract_skills_guru(row):\n",
    "    skills = []\n",
    "    for i,val in enumerate(row):\n",
    "        if val == 1:\n",
    "            skills.append(str(i))\n",
    "    return skills \n",
    "\n",
    "def importGuruData(experts_filename='datasets/guru/guru_experts.csv', tasks_filename='datasets/guru/guru_tasks.csv'):\n",
    "    #Extract tasks skills as list\n",
    "    guru_tasks_df = pd.read_csv(tasks_filename, header=None)\n",
    "    print(\"Guru tasks df shape: \", guru_tasks_df.shape)\n",
    "    guru_tasks_df['Task_Skills'] = guru_tasks_df.apply(lambda row: extract_skills_guru(row), axis=1)\n",
    "    task_skills_list = guru_tasks_df.Task_Skills.to_list()\n",
    "    task_skills_list = task_skills_list[0:-1]\n",
    "    \n",
    "    #Extract experts skills as list\n",
    "    guru_experts_df = pd.read_csv(experts_filename, header=None)\n",
    "    print(\"Guru experts df shape: \", guru_experts_df.shape)\n",
    "    guru_experts_df['Expert_Skills'] = guru_experts_df.apply(lambda row: extract_skills_guru(row), axis=1)\n",
    "    expert_skills_list = guru_experts_df.Expert_Skills.to_list()\n",
    "    expert_skills_list = expert_skills_list[0:-1]\n",
    "\n",
    "    print(\"Imported Guru dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,e = importGuruData()\n",
    "GuruTest = TFP.TeamFormationProblem(t, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDict, F_vals, workLoad_vals = GuruTest.computeTaskAssigment(algorithms=['no_update_greedy'], lambdaVal=0.1)\n",
    "# runtimeDict, F_vals, workLoad_vals = GuruTest.computeTaskAssigment(algorithms=['lazy_greedy'], lambdaVal=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import IMDB Data\n",
    "def importIMDBData(experts_filename, tasks_filename):\n",
    "    with open(experts_filename, 'r') as f:\n",
    "        expert_skills_list = json.loads(f.read())\n",
    "    \n",
    "    with open(tasks_filename, 'r') as f:\n",
    "        task_skills_list = json.loads(f.read())\n",
    "\n",
    "    print(\"Imported IMDB dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list, \n",
    "\n",
    "#Run algorithm on IMDB datasets\n",
    "def testIMDBDatasets(write_flag, algoList):\n",
    "    imdb_data_path = 'datasets/imdb/'\n",
    "    movieYears = [2015, 2018, 2020]\n",
    "\n",
    "    if write_flag:\n",
    "        runTimeStamp = str(time.strftime(\"%m-%d-%H:%M:%S\", time.localtime(time.time())))\n",
    "        imdb_outfilename = \"experiments/imdb_\" + runTimeStamp + \".txt\"\n",
    "        outfile_imdb = open(imdb_outfilename, \"a\")\n",
    "        outfile_imdb.write(\"IMDB dataset Team-Formation Algorithms: {}\\n\".format(runTimeStamp))\n",
    "\n",
    "    for y in movieYears:\n",
    "        experts_file = imdb_data_path + 'imdb_experts_' + str(y) + '.txt'\n",
    "        tasks_file = imdb_data_path + 'imdb_tasks_' + str(y) + '.txt'\n",
    "        print(\"IMDB Dataset: {}, {}\".format('imdb_experts_' + str(y), 'imdb_tasks_' + str(y)))\n",
    "\n",
    "        imdb_tasks, imdb_experts = importIMDBData(experts_file, tasks_file)\n",
    "        IMDBTest = TFP.TeamFormationProblem(imdb_tasks[0:600], imdb_experts[0:100])\n",
    "\n",
    "        rt_dict, f_dict, workload_dict, coverageList = IMDBTest.computeTaskAssigment(algorithms=algoList, plot_flag=False)\n",
    "        coverageListString = \"\"\n",
    "        for c_i in coverageList:\n",
    "            c_i_str = \", \"+str(np.round(c_i, 2))\n",
    "            coverageListString += c_i_str\n",
    "        print(coverageListString)\n",
    "        #Write output to file\n",
    "        if write_flag:\n",
    "            runInfo = \"\\nIMDB movieYear = {}, Experts = {}, Tasks = {}\".format(str(y), str(IMDBTest.n), str(IMDBTest.m))\n",
    "            outfile_imdb.write(runInfo)\n",
    "\n",
    "            f_info = \"\\nAlgorithm Objectives (F_max): Lazy Greedy = {}; No-Update-Greedy = {}; Task Greedy = {}; Random = {};\\\n",
    "                \".format(f_dict['lazyGreedy'], f_dict['noUpdateGreedy'], f_dict['taskGreedy'], f_dict['random'])\n",
    "            outfile_imdb.write(f_info)   \n",
    "\n",
    "            wload_info = \"\\nAlgorithm optimal workloads: Lazy Greedy = {}; No-Update-Greedy = {}; Task Greedy = {}; Random = {};\\\n",
    "                \".format(workload_dict['lazyGreedy'], workload_dict['noUpdateGreedy'], workload_dict['taskGreedy'], workload_dict['random'])\n",
    "            outfile_imdb.write(wload_info)   \n",
    "\n",
    "            runtimeInfo = \"\\nAlgorithm Runtimes: Total = {:.3f}s; Lazy Greedy = {:.3f}s; No-Update-Greedy = {:.3f}s; Task Greedy = {:.3f}s; Random = {:.3f}s;\\\n",
    "                \\n\".format(rt_dict['total'], rt_dict['lazyGreedy'], rt_dict['noUpdateGreedy'], rt_dict['taskGreedy'], rt_dict['random'])\n",
    "            outfile_imdb.write(runtimeInfo)\n",
    "\n",
    "            outfile_imdb.write(\"\\nCoverage List: {}\".format(coverageListString))\n",
    "\n",
    "    \n",
    "    if write_flag:\n",
    "        outfile_imdb.close()\n",
    "\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testIMDBDatasets(write_flag=True, algoList=['lazy_greedy', 'random', 'no_update_greedy', 'task_greedy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get coverage lists\n",
    "imdb_data_path = 'datasets/imdb/'\n",
    "y = 2018\n",
    "experts_file = imdb_data_path + 'imdb_experts_' + str(y) + '.txt'\n",
    "tasks_file = imdb_data_path + 'imdb_tasks_' + str(y) + '.txt'\n",
    "print(\"IMDB Dataset: {}, {}\".format('imdb_experts_' + str(y), 'imdb_tasks_' + str(y)))\n",
    "\n",
    "imdb_tasks, imdb_experts = importIMDBData(experts_file, tasks_file)\n",
    "IMDBTest = TFP.TeamFormationProblem(imdb_tasks, imdb_experts, max_workload_threshold=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDict, F_vals, workLoad_vals = IMDBTest.computeTaskAssigment(algorithms=['random', 'no_update_greedy', 'task_greedy'], lambdaVal=0.05)\n",
    "#runtimeDict, F_vals, workLoad_vals = IMDBTest.computeTaskAssigment(algorithms=['no_update_greedy'], lambdaVal=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covDict = IMDBCoverages.getStepCoverageValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_path = 'datasets/imdb/'\n",
    "y = 2015\n",
    "experts_file = imdb_data_path + 'imdb_experts_' + str(y) + '.txt'\n",
    "tasks_file = imdb_data_path + 'imdb_tasks_' + str(y) + '.txt'\n",
    "print(\"IMDB Dataset: {}, {}\".format('imdb_experts_' + str(y), 'imdb_tasks_' + str(y)))\n",
    "\n",
    "imdb_tasks, imdb_experts = importIMDBData(experts_file, tasks_file)\n",
    "IMDBLambdaTest = TFP.TeamFormationProblem(imdb_tasks[:1000], imdb_experts[300:600], max_workload_threshold=100)\n",
    "\n",
    "t_arr, f_dict, t_maxArr, f_maxArr = IMDBLambdaTest.testLambdaTaskAssignment(algorithms=['lazy_greedy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot F_i for different Lambda for Lazy Greedy\n",
    "plt.figure(figsize=(9,6))\n",
    "#for l_val in f_dict.keys():\n",
    "    #plt.plot(t_arr, f_dict[l_val], label='Lambda={:.3f}'.format(l_val))\n",
    "\n",
    "# Plot the max values\n",
    "plt.plot(t_maxArr, f_maxArr, '--*', label='Max F_i')\n",
    "\n",
    "# title_text = 'Lazy Greedy Performance by varying Lambda (IMDB_2015)'\n",
    "# plt.title(title_text, fontsize=12)\n",
    "plt.xlabel('Workload Threshold, T_i', fontsize=12)\n",
    "plt.ylabel('Coverage, C(A)', fontsize=12)\n",
    "\n",
    "\n",
    "lambda_arr = [0.3, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100]\n",
    "i=0\n",
    "# zip joins x and y coordinates in pairs\n",
    "for x,y in zip(t_maxArr,f_maxArr):\n",
    "    label = \"{:.1f}\".format(lambda_arr[i])\n",
    "    i += 1\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,y), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibsonomy Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Bibsonomy datasets\n",
    "def importBibsonomyData(experts_filename, tasks_filename):\n",
    "    with open(experts_filename, 'r') as f:\n",
    "        expert_skills_list = json.loads(f.read())\n",
    "    \n",
    "    with open(tasks_filename, 'r') as f:\n",
    "        task_skills_list = json.loads(f.read())\n",
    "\n",
    "    print(\"Imported Bibsonomy dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list\n",
    "\n",
    "#Run algorithm on Bibsonomy datasets\n",
    "def testBibsonomyDatasets(write_flag, algoList):\n",
    "    bibsonomy_data_path = 'datasets/bibsonomy/'\n",
    "    movieYears = [2010, 2015, 2020]\n",
    "\n",
    "    if write_flag:\n",
    "        runTimeStamp = str(time.strftime(\"%m-%d-%H:%M:%S\", time.localtime(time.time())))\n",
    "        bibs_outfilename = \"experiments/bibsonomy_\" + runTimeStamp + \".txt\"\n",
    "        outfile_bibsonomy = open(bibs_outfilename, \"a\")\n",
    "        outfile_bibsonomy.write(\"Bibsonomy dataset Team-Formation Algorithms: {}\\n\".format(runTimeStamp))\n",
    "\n",
    "    for y in movieYears:\n",
    "        experts_file = bibsonomy_data_path + 'bibsonomy_experts_' + str(y) + '.txt'\n",
    "        tasks_file = bibsonomy_data_path + 'bibsonomy_tasks_' + str(y) + '.txt'\n",
    "        print(\"\\nBibsonomy Dataset: {}, {}\".format('bibsonomy_experts_' + str(y), 'bibsonomy_tasks_' + str(y)))\n",
    "\n",
    "        bib_tasks, bib_experts = importBibsonomyData(experts_file, tasks_file)\n",
    "        BibsonomyTest = TFP.TeamFormationProblem(bib_tasks[0:500], bib_experts[0:200])\n",
    "\n",
    "        rt_dict, f_dict, workload_dict = BibsonomyTest.computeTaskAssigment(algorithms=algoList, plot_flag=False)\n",
    "\n",
    "        #Write output to file\n",
    "        if write_flag:\n",
    "            runInfo = \"\\nBibsonomy paperYear = {}, Experts = {}, Tasks = {}\".format(str(y), str(BibsonomyTest.n), str(BibsonomyTest.m))\n",
    "            outfile_bibsonomy.write(runInfo)\n",
    "\n",
    "            f_info = \"\\nAlgorithm Objectives (F_max): Lazy Greedy = {}; No-Update-Greedy = {}; Task Greedy = {}; Random = {};\\\n",
    "                \".format(f_dict['lazyGreedy'], f_dict['noUpdateGreedy'], f_dict['taskGreedy'], f_dict['random'])\n",
    "            outfile_bibsonomy.write(f_info)   \n",
    "\n",
    "            wload_info = \"\\nAlgorithm optimal workloads: Lazy Greedy = {}; No-Update-Greedy = {}; Task Greedy = {}; Random = {};\\\n",
    "                \".format(workload_dict['lazyGreedy'], workload_dict['noUpdateGreedy'], workload_dict['taskGreedy'], workload_dict['random'])\n",
    "            outfile_bibsonomy.write(wload_info)   \n",
    "\n",
    "            runtimeInfo = \"\\nAlgorithm Runtimes: Total = {:.3f}s; Lazy Greedy = {:.3f}s; No-Update-Greedy = {:.3f}s; Task Greedy = {:.3f}s; Random = {:.3f}s;\\\n",
    "                \\n\".format(rt_dict['total'], rt_dict['lazyGreedy'], rt_dict['noUpdateGreedy'], rt_dict['taskGreedy'], rt_dict['random'])\n",
    "            outfile_bibsonomy.write(runtimeInfo)\n",
    "    \n",
    "    if write_flag:\n",
    "        outfile_bibsonomy.close()\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testBibsonomyDatasets(write_flag=True, algoList=['lazy_greedy', 'random', 'no_update_greedy', 'task_greedy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibsonomy_data_path = 'datasets/bibsonomy/'\n",
    "y=2015\n",
    "experts_file = bibsonomy_data_path + 'bibsonomy_experts_' + str(y) + '.txt'\n",
    "tasks_file = bibsonomy_data_path + 'bibsonomy_tasks_' + str(y) + '.txt'\n",
    "print(\"\\nBibsonomy Dataset: {}, {}\".format('bibsonomy_experts_' + str(y), 'bibsonomy_tasks_' + str(y)))\n",
    "\n",
    "bib_tasks, bib_experts = importBibsonomyData(experts_file, tasks_file)\n",
    "BibsonomyTest = TFP.TeamFormationProblem(bib_tasks, bib_experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDict, F_vals, workLoad_vals = BibsonomyTest.computeTaskAssigment(algorithms=['random', 'no_update_greedy', 'task_greedy'], lambdaVal=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot F_i for different Lambda for Lazy Greedy\n",
    "# plt.figure(figsize=(9,6))\n",
    "# for l_val in Fi_dict.keys():\n",
    "#     plt.plot(T_arr, Fi_dict[l_val], label='Lambda={:.3f}'.format(l_val))\n",
    "\n",
    "# # Plot the max values\n",
    "# plt.plot(TMaxArr, FMaxArr, '--*', label='Max F_i')\n",
    "\n",
    "# title_text = 'Lazy Greedy Performance by varying Lambda (Bibsonomy_2015)'\n",
    "# plt.title(title_text, fontsize=12)\n",
    "# plt.xlabel('Workload Threshold, T_i')\n",
    "# plt.ylabel('F_i')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_threshold_arr = [5,10,40,80,100,150,200]\n",
    "# rev_rt_arr, reg_rt_arr = [],[]\n",
    "# for thresh in max_threshold_arr:\n",
    "#     FreelancerTest = TFP.TeamFormationProblem(t[0:200], e[0:200], max_workload_threshold=thresh)\n",
    "#     rev_rt, reg_rt = FreelancerTest.compare_Methods()\n",
    "#     rev_rt_arr.append(rev_rt)\n",
    "#     reg_rt_arr.append(reg_rt)\n",
    "\n",
    "#Plot Runtimes\n",
    "# plt.figure(figsize=(9,6))\n",
    "# plt.plot(max_threshold_arr, rev_rt_arr, label='Reverse Threshold Runtime')\n",
    "# plt.plot(max_threshold_arr, reg_rt_arr, label='Regular Lazy Runtime')\n",
    "\n",
    "# title_text = 'Reverse Threshold vs. Regular Lazy runtimes'\n",
    "# plt.title(title_text, fontsize=11)\n",
    "# plt.xlabel('Max Threshold, T_i')\n",
    "# plt.ylabel('Runtime, s')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "#FreelancerTest.compute_reverseThreshold()\n",
    "#FreelancerTest.compareTest_Lazy_Stochastic_Assignments()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
