{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Team Formation framework with real datasets\n",
    "## Balancing Task Coverage vs. Maximum Expert Load\n",
    "## Karan Vombatkere, Spring 2022\n",
    "\n",
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json, time\n",
    "import TeamFormationProblem as TFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibs2020_covList = [90.72,163.62,217.13,250.47,273.55,290.12,304.03,317.9,328.97,339.57,349.45,357.32,365.48,373.27,380.27,386.68,392.17,397.12,402.12,\n",
    "406.7,411.03,415.37,419.98,423.98,427.98,431.65,435.98,440.98,445.32,449.65,454.23,456.9,460.3,463.57,466.47,469.83,472.93,474.37,475.6,477.38,478.58,\n",
    "479.42,480.42,481.67,482.0,482.92,483.75,484.83,486.0,486.67,487.33,488.0,489.0,489.67,490.17,490.83,491.5,492.17,492.83,493.17,493.5,493.83,494.17,\n",
    "494.5,494.83,495.17,495.5,495.83,496.17,496.5,496.83,497.17,497.5,497.83,498.17,498.5,498.83,499.17,499.5,499.83,500.17,500.5,500.75,501.0,501.25,\n",
    "501.45,501.65,501.85,502.05,502.05,502.05,502.05,502.05,502.05,502.05,502.05,502.05,502.05,502.05,502.05]\n",
    "\n",
    "bibs2015_covList = [1636.06,2962.07,3976.15,4773.0,5345.78,5810.93,6201.01,6538.07,6816.47,7051.95,7253.95,7437.05,7577.0,7686.22,7783.92,7868.37,7937.9,\n",
    "7996.32,8046.61,8094.57,8137.25,8175.47,8213.75,8251.69,8280.44,8305.07,8326.32,8345.87,8365.06,8382.97,8399.72,8414.84,8427.81,8437.85,8448.09,8458.94,\n",
    "8468.02,8476.77,8486.41,8494.05,8500.45,8508.31,8516.33,8525.04,8530.95,8535.84,8540.65,8544.1,8548.18,8550.25]\n",
    "\n",
    "bibs2010_covList = [16106.41,20314.17,20858.87,21085.92,21207.77,21265.34,21305.94,21330.59,21347.24,21358.95,21374.05]\n",
    "\n",
    "imdb2020_covList = [2056.52,3838.52,5505.95,6638.51,7306.9,7640.89,7783.11,7791.44,7796.42,7800.77,7804.77,7808.77,7812.77,7816.77,7820.77,7824.77,7828.77,\n",
    "7832.77,7836.77,7840.77,7844.77,7848.77,7852.77,7854.93,7856.27,7857.43,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,\n",
    "7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0,7858.0]\n",
    "\n",
    "imdb2018_covList = [3661.5,6743.72,9526.9,11258.07,12233.38,12759.82,12986.41,13017.97,13022.57,13027.31,13030.31,13033.63,13036.63,13039.63,13042.63,13045.63,\n",
    "13048.63,13051.63,13054.63,13057.63,13060.63,13063.63,13066.63,13069.63,13072.63,13075.63,13078.63,13081.63,13084.63,13087.63,13090.63,13093.63,13096.63,13099.63,\n",
    "13102.63,13105.63,13108.63,13111.63,13114.63,13117.63,13120.63,13123.63,13126.63,13129.63,13132.63,13135.63,13138.63,13141.63,13144.63,13147.63]\n",
    "\n",
    "imdb2015_covList = [5286.97,9765.69,13534.03,15750.51,16923.74,17604.37,17848.23,17866.78,17880.91,17894.89,17906.89,17918.72,17930.72,17943.72,17956.22,17968.72,\n",
    "17981.22,17994.22,18006.72,18019.22,18031.72,18043.06,18055.56,18067.39,18078.89,18090.72,18098.72,18102.89,18106.25,18106.25,18106.25,18106.25,18106.25,18106.25,\n",
    "18106.25,18106.25,18106.25,18106.25,18106.25,18106.25,18106.25,18106.25,18106.25,18106.25,18106.25,18106.25,18106.25,18106.25,18106.25,18106.25]\n",
    "\n",
    "freelancer_covList = [592.78, 770.35, 853.98, 896.97, 927.43, 939.47, 944.88, 950.05, 954.1 , 958.07, 961.38, 965.37, 968.85, 972.1 , 974.1 , 976.4 ,\n",
    "978.58, 980.87, 982.63, 984.12, 985.1 , 985.8 , 986.4 , 987.38, 988.32, 989.25, 990.1 , 990.95, 991.4 , 991.8 , 992.  , 992.  ,\n",
    "992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  , 992.  ]\n",
    "\n",
    "Guru_covList = [2759.97, 3068.83, 3133.5, 3152.19, 3161.93, 3168.25, 3172.03, 3174.32, 3177.28, 3179.17, 3181.28, 3182.78, 3184.14, 3185.58, 3186.79, 3187.90,\n",
    "3188.81, 3189.60, 3190.26, 3190.85, 3191.40, 3191.87, 3192.20, 3192.54, 3192.85, 3193.08, 3193.27, 3193.27, 3193.27, 3193.27]\n",
    "\n",
    "\n",
    "# lambdaList = [0.001,0.05, 0.1, 0.25, 0.5, 1, 2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given list of coverages, and list of lambda values - find max for each lambda\n",
    "def findBestLambda(coverageList, lambdaVals, plot_name, font_size):\n",
    "    #Plot lambda curve of max coverages and max loads\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    lambdaMaxDict = {'lambdas': [], 'maxCoverages':[], 'workLoads': []}\n",
    "\n",
    "    workload_vals = [10,30,50,70,90,110,130,150,170,190,210]\n",
    "\n",
    "    for l_val in lambdaVals:\n",
    "        F_prev = 0 #set F_prev to 0\n",
    "\n",
    "        for i, c_i in enumerate(coverageList):\n",
    "            thresh = i+1\n",
    "            #thresh = workload_vals[i]\n",
    "            F_val = (l_val * c_i) - thresh\n",
    "            \n",
    "            if F_val <= F_prev:\n",
    "                lambdaMaxDict['lambdas'].append(l_val)\n",
    "                lambdaMaxDict['maxCoverages'].append(coverageList[i-1])\n",
    "                lambdaMaxDict['workLoads'].append(i)\n",
    "                print(\"Max value found. Lambda={}, Max Coverage={:.2f}, Work Load={}\".format(l_val, coverageList[i-1], i))\n",
    "                break\n",
    "            \n",
    "            F_prev = F_val\n",
    "        \n",
    "        if F_val >= F_prev:\n",
    "            # lambdaMaxDict['lambdas'].append(l_val)\n",
    "            # lambdaMaxDict['maxCoverages'].append(coverageList[i])\n",
    "            # lambdaMaxDict['workLoads'].append(thresh)\n",
    "            print(\"Max value not found. Lambda={}, Max Coverage={:.2f}, Work Load={}\".format(l_val, coverageList[i-1], i))\n",
    "    \n",
    "    # Plot the max values\n",
    "    plt.plot(lambdaMaxDict['workLoads'], lambdaMaxDict['maxCoverages'], '--*', label=plot_name)\n",
    "    plt.rc('xtick', labelsize=font_size)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=font_size)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=font_size)\n",
    "\n",
    "    # title_text = 'Threshold Greedy varying Lambda (Guru)'\n",
    "    # plt.title(title_text, fontsize=12)\n",
    "    plt.xlabel('$L_{max}(A)$', fontsize=font_size)\n",
    "    plt.ylabel('$C(A)$', fontsize=font_size)\n",
    "\n",
    "    i=0\n",
    "    # zip joins x and y coordinates in pairs\n",
    "    for x,y in zip(lambdaMaxDict['workLoads'],lambdaMaxDict['maxCoverages']):\n",
    "        label = \"$\\lambda={}$\".format(lambdaVals[i])\n",
    "        i += 1\n",
    "        plt.annotate(label, # this is the text\n",
    "                    (x,y), # these are the coordinates to position the label\n",
    "                    textcoords=\"offset points\", # how to position the text\n",
    "                    xytext=(5,-12), # distance from text to points (x,y)\n",
    "                    ha='center',\n",
    "                    fontsize = font_size) # horizontal alignment can be left, right or center\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdaList_bibs2015 = [0.001, 0.005, 0.05, 0.1, 0.3]\n",
    "lambdaList_bibs2020 = [0.05, 0.1, 0.2, 0.3, 1, 4]\n",
    "\n",
    "lambdaList_freelancer = [0.005, 0.01, 0.1, 1, 4]\n",
    "lambdaList_guru = [0.005, 0.05, 0.1, 0.5, 1, 4]\n",
    "\n",
    "lambdaList_imdb2015 = [0.001, 0.05, 0.1, 2]\n",
    "lambdaList_imdb2018 = [0.001, 0.005, 0.05, 0.3]\n",
    "lambdaList_imdb2020 = [0.001, 0.1, 0.5, 2]\n",
    "\n",
    "plottingList = [(bibs2015_covList, lambdaList_bibs2015, 'Bibsonomy-2015'), \n",
    "                (bibs2020_covList, lambdaList_bibs2020, 'Bibsonomy-2020'),\n",
    "                (freelancer_covList, lambdaList_freelancer, 'Freelancer'),\n",
    "                (Guru_covList, lambdaList_guru, 'Guru'),\n",
    "                (imdb2015_covList, lambdaList_imdb2015, 'IMDB-2015'),\n",
    "                (imdb2018_covList, lambdaList_imdb2018, 'IMDB-2018'),\n",
    "                (imdb2020_covList, lambdaList_imdb2020, 'IMDB-2020')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plotDetails in plottingList:\n",
    "    findBestLambda(plotDetails[0], plotDetails[1], plot_name = plotDetails[2], font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freelancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Freelancer data\n",
    "#Freelancer from DropBox link: https://www.dropbox.com/sh/8zpsi1etvvvvj5k/AAD-J9ZQmSsbnSmEILBMD9uxa/datasets/real?dl=0&subfolder_nav_tracking=1\n",
    "#freelance_experts.csv and freelance_projects.csv\n",
    "\n",
    "def extract_skills(row):\n",
    "    skills = []\n",
    "    for i,val in enumerate(row):\n",
    "        if val == 1:\n",
    "            skills.append(str(i))\n",
    "    return skills            \n",
    "\n",
    "    \n",
    "def importFreelancerData(experts_filename='datasets/freelancer/freelancer_experts.csv', tasks_filename='datasets/freelancer/freelancer_projects.csv'):\n",
    "    #Extract tasks skills as list\n",
    "    freelance_tasks_df = pd.read_csv(tasks_filename, header=None)\n",
    "    print(\"Freelancer tasks df shape: \", freelance_tasks_df.shape)\n",
    "    freelance_tasks_df['Task_Skills'] = freelance_tasks_df.apply(lambda row: extract_skills(row), axis=1)\n",
    "    task_skills_list = freelance_tasks_df.Task_Skills.to_list()\n",
    "    \n",
    "    #Extract experts skills as list\n",
    "    freelance_experts_df = pd.read_csv(experts_filename, header=None)\n",
    "    print(\"Freelancer experts df shape: \", freelance_experts_df.shape)\n",
    "    freelance_experts_df['Expert_Skills'] = freelance_experts_df.apply(lambda row: extract_skills(row), axis=1)\n",
    "    expert_skills_list = freelance_experts_df.Expert_Skills.to_list()\n",
    "\n",
    "    print(\"Imported Freelancer dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,e = importFreelancerData()\n",
    "FreelancerTest = TFP.TeamFormationProblem(t, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDict, F_vals, workLoad_vals = FreelancerTest.computeTaskAssigment(algorithms=['random', 'no_update_greedy','task_greedy'], lambdaVal=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freelancerCovList = FreelancerTest.getCoverageValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guru Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guru Dataset\n",
    "def extract_skills_guru(row):\n",
    "    skills = []\n",
    "    for i,val in enumerate(row):\n",
    "        if val == 1:\n",
    "            skills.append(str(i))\n",
    "    return skills \n",
    "\n",
    "def importGuruData(experts_filename='datasets/guru/guru_experts.csv', tasks_filename='datasets/guru/guru_tasks.csv'):\n",
    "    #Extract tasks skills as list\n",
    "    guru_tasks_df = pd.read_csv(tasks_filename, header=None)\n",
    "    print(\"Guru tasks df shape: \", guru_tasks_df.shape)\n",
    "    guru_tasks_df['Task_Skills'] = guru_tasks_df.apply(lambda row: extract_skills_guru(row), axis=1)\n",
    "    task_skills_list = guru_tasks_df.Task_Skills.to_list()\n",
    "    task_skills_list = task_skills_list[0:-1]\n",
    "    \n",
    "    #Extract experts skills as list\n",
    "    guru_experts_df = pd.read_csv(experts_filename, header=None)\n",
    "    print(\"Guru experts df shape: \", guru_experts_df.shape)\n",
    "    guru_experts_df['Expert_Skills'] = guru_experts_df.apply(lambda row: extract_skills_guru(row), axis=1)\n",
    "    expert_skills_list = guru_experts_df.Expert_Skills.to_list()\n",
    "    expert_skills_list = expert_skills_list[0:-1]\n",
    "\n",
    "    print(\"Imported Guru dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,e = importGuruData()\n",
    "GuruTest = TFP.TeamFormationProblem(t, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtimeDict, F_vals, workLoad_vals = GuruTest.computeTaskAssigment(algorithms=['lazy_greedy', 'random', 'no_update_greedy','task_greedy'], lambdaVal=0.1)\n",
    "runtimeDict, F_vals, workLoad_vals = GuruTest.computeTaskAssigment(algorithms=['lazy_greedy'], lambdaVal=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import IMDB Data\n",
    "def importIMDBData(experts_filename, tasks_filename):\n",
    "    with open(experts_filename, 'r') as f:\n",
    "        expert_skills_list = json.loads(f.read())\n",
    "    \n",
    "    with open(tasks_filename, 'r') as f:\n",
    "        task_skills_list = json.loads(f.read())\n",
    "\n",
    "    print(\"Imported IMDB dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list, \n",
    "\n",
    "#Run algorithm on IMDB datasets\n",
    "def testIMDBDatasets(write_flag, algoList):\n",
    "    imdb_data_path = 'datasets/imdb/'\n",
    "    movieYears = [2015, 2018, 2020]\n",
    "\n",
    "    if write_flag:\n",
    "        runTimeStamp = str(time.strftime(\"%m-%d-%H:%M:%S\", time.localtime(time.time())))\n",
    "        imdb_outfilename = \"experiments/imdb_\" + runTimeStamp + \".txt\"\n",
    "        outfile_imdb = open(imdb_outfilename, \"a\")\n",
    "        outfile_imdb.write(\"IMDB dataset Team-Formation Algorithms: {}\\n\".format(runTimeStamp))\n",
    "\n",
    "    for y in movieYears:\n",
    "        experts_file = imdb_data_path + 'imdb_experts_' + str(y) + '.txt'\n",
    "        tasks_file = imdb_data_path + 'imdb_tasks_' + str(y) + '.txt'\n",
    "        print(\"IMDB Dataset: {}, {}\".format('imdb_experts_' + str(y), 'imdb_tasks_' + str(y)))\n",
    "\n",
    "        imdb_tasks, imdb_experts = importIMDBData(experts_file, tasks_file)\n",
    "        IMDBTest = TFP.TeamFormationProblem(imdb_tasks[0:600], imdb_experts[0:100])\n",
    "\n",
    "        rt_dict, f_dict, workload_dict, coverageList = IMDBTest.computeTaskAssigment(algorithms=algoList, plot_flag=False)\n",
    "        coverageListString = \"\"\n",
    "        for c_i in coverageList:\n",
    "            c_i_str = \", \"+str(np.round(c_i, 2))\n",
    "            coverageListString += c_i_str\n",
    "        print(coverageListString)\n",
    "        #Write output to file\n",
    "        if write_flag:\n",
    "            runInfo = \"\\nIMDB movieYear = {}, Experts = {}, Tasks = {}\".format(str(y), str(IMDBTest.n), str(IMDBTest.m))\n",
    "            outfile_imdb.write(runInfo)\n",
    "\n",
    "            f_info = \"\\nAlgorithm Objectives (F_max): Lazy Greedy = {}; No-Update-Greedy = {}; Task Greedy = {}; Random = {};\\\n",
    "                \".format(f_dict['lazyGreedy'], f_dict['noUpdateGreedy'], f_dict['taskGreedy'], f_dict['random'])\n",
    "            outfile_imdb.write(f_info)   \n",
    "\n",
    "            wload_info = \"\\nAlgorithm optimal workloads: Lazy Greedy = {}; No-Update-Greedy = {}; Task Greedy = {}; Random = {};\\\n",
    "                \".format(workload_dict['lazyGreedy'], workload_dict['noUpdateGreedy'], workload_dict['taskGreedy'], workload_dict['random'])\n",
    "            outfile_imdb.write(wload_info)   \n",
    "\n",
    "            runtimeInfo = \"\\nAlgorithm Runtimes: Total = {:.3f}s; Lazy Greedy = {:.3f}s; No-Update-Greedy = {:.3f}s; Task Greedy = {:.3f}s; Random = {:.3f}s;\\\n",
    "                \\n\".format(rt_dict['total'], rt_dict['lazyGreedy'], rt_dict['noUpdateGreedy'], rt_dict['taskGreedy'], rt_dict['random'])\n",
    "            outfile_imdb.write(runtimeInfo)\n",
    "\n",
    "            outfile_imdb.write(\"\\nCoverage List: {}\".format(coverageListString))\n",
    "\n",
    "    \n",
    "    if write_flag:\n",
    "        outfile_imdb.close()\n",
    "\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testIMDBDatasets(write_flag=True, algoList=['lazy_greedy', 'random', 'no_update_greedy', 'task_greedy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get coverage lists\n",
    "imdb_data_path = 'datasets/imdb/'\n",
    "y = 2018\n",
    "experts_file = imdb_data_path + 'imdb_experts_' + str(y) + '.txt'\n",
    "tasks_file = imdb_data_path + 'imdb_tasks_' + str(y) + '.txt'\n",
    "print(\"IMDB Dataset: {}, {}\".format('imdb_experts_' + str(y), 'imdb_tasks_' + str(y)))\n",
    "\n",
    "imdb_tasks, imdb_experts = importIMDBData(experts_file, tasks_file)\n",
    "IMDBTest = TFP.TeamFormationProblem(imdb_tasks, imdb_experts, max_workload_threshold=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDict, F_vals, workLoad_vals = IMDBTest.computeTaskAssigment(algorithms=['random', 'no_update_greedy', 'task_greedy'], lambdaVal=0.05)\n",
    "#runtimeDict, F_vals, workLoad_vals = IMDBTest.computeTaskAssigment(algorithms=['no_update_greedy'], lambdaVal=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covDict = IMDBCoverages.getStepCoverageValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_path = 'datasets/imdb/'\n",
    "y = 2015\n",
    "experts_file = imdb_data_path + 'imdb_experts_' + str(y) + '.txt'\n",
    "tasks_file = imdb_data_path + 'imdb_tasks_' + str(y) + '.txt'\n",
    "print(\"IMDB Dataset: {}, {}\".format('imdb_experts_' + str(y), 'imdb_tasks_' + str(y)))\n",
    "\n",
    "imdb_tasks, imdb_experts = importIMDBData(experts_file, tasks_file)\n",
    "IMDBLambdaTest = TFP.TeamFormationProblem(imdb_tasks[:1000], imdb_experts[300:600], max_workload_threshold=100)\n",
    "\n",
    "t_arr, f_dict, t_maxArr, f_maxArr = IMDBLambdaTest.testLambdaTaskAssignment(algorithms=['lazy_greedy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot F_i for different Lambda for Lazy Greedy\n",
    "plt.figure(figsize=(9,6))\n",
    "#for l_val in f_dict.keys():\n",
    "    #plt.plot(t_arr, f_dict[l_val], label='Lambda={:.3f}'.format(l_val))\n",
    "\n",
    "# Plot the max values\n",
    "plt.plot(t_maxArr, f_maxArr, '--*', label='Max F_i')\n",
    "\n",
    "# title_text = 'Lazy Greedy Performance by varying Lambda (IMDB_2015)'\n",
    "# plt.title(title_text, fontsize=12)\n",
    "plt.xlabel('Workload Threshold, T_i', fontsize=12)\n",
    "plt.ylabel('Coverage, C(A)', fontsize=12)\n",
    "\n",
    "\n",
    "lambda_arr = [0.3, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100]\n",
    "i=0\n",
    "# zip joins x and y coordinates in pairs\n",
    "for x,y in zip(t_maxArr,f_maxArr):\n",
    "    label = \"{:.1f}\".format(lambda_arr[i])\n",
    "    i += 1\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,y), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibsonomy Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Bibsonomy datasets\n",
    "def importBibsonomyData(experts_filename, tasks_filename):\n",
    "    with open(experts_filename, 'r') as f:\n",
    "        expert_skills_list = json.loads(f.read())\n",
    "    \n",
    "    with open(tasks_filename, 'r') as f:\n",
    "        task_skills_list = json.loads(f.read())\n",
    "\n",
    "    print(\"Imported Bibsonomy dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list\n",
    "\n",
    "#Run algorithm on Bibsonomy datasets\n",
    "def testBibsonomyDatasets(write_flag, algoList):\n",
    "    bibsonomy_data_path = 'datasets/bibsonomy/'\n",
    "    movieYears = [2010, 2015, 2020]\n",
    "\n",
    "    if write_flag:\n",
    "        runTimeStamp = str(time.strftime(\"%m-%d-%H:%M:%S\", time.localtime(time.time())))\n",
    "        bibs_outfilename = \"experiments/bibsonomy_\" + runTimeStamp + \".txt\"\n",
    "        outfile_bibsonomy = open(bibs_outfilename, \"a\")\n",
    "        outfile_bibsonomy.write(\"Bibsonomy dataset Team-Formation Algorithms: {}\\n\".format(runTimeStamp))\n",
    "\n",
    "    for y in movieYears:\n",
    "        experts_file = bibsonomy_data_path + 'bibsonomy_experts_' + str(y) + '.txt'\n",
    "        tasks_file = bibsonomy_data_path + 'bibsonomy_tasks_' + str(y) + '.txt'\n",
    "        print(\"\\nBibsonomy Dataset: {}, {}\".format('bibsonomy_experts_' + str(y), 'bibsonomy_tasks_' + str(y)))\n",
    "\n",
    "        bib_tasks, bib_experts = importBibsonomyData(experts_file, tasks_file)\n",
    "        BibsonomyTest = TFP.TeamFormationProblem(bib_tasks[0:500], bib_experts[0:200])\n",
    "\n",
    "        rt_dict, f_dict, workload_dict = BibsonomyTest.computeTaskAssigment(algorithms=algoList, plot_flag=False)\n",
    "\n",
    "        #Write output to file\n",
    "        if write_flag:\n",
    "            runInfo = \"\\nBibsonomy paperYear = {}, Experts = {}, Tasks = {}\".format(str(y), str(BibsonomyTest.n), str(BibsonomyTest.m))\n",
    "            outfile_bibsonomy.write(runInfo)\n",
    "\n",
    "            f_info = \"\\nAlgorithm Objectives (F_max): Lazy Greedy = {}; No-Update-Greedy = {}; Task Greedy = {}; Random = {};\\\n",
    "                \".format(f_dict['lazyGreedy'], f_dict['noUpdateGreedy'], f_dict['taskGreedy'], f_dict['random'])\n",
    "            outfile_bibsonomy.write(f_info)   \n",
    "\n",
    "            wload_info = \"\\nAlgorithm optimal workloads: Lazy Greedy = {}; No-Update-Greedy = {}; Task Greedy = {}; Random = {};\\\n",
    "                \".format(workload_dict['lazyGreedy'], workload_dict['noUpdateGreedy'], workload_dict['taskGreedy'], workload_dict['random'])\n",
    "            outfile_bibsonomy.write(wload_info)   \n",
    "\n",
    "            runtimeInfo = \"\\nAlgorithm Runtimes: Total = {:.3f}s; Lazy Greedy = {:.3f}s; No-Update-Greedy = {:.3f}s; Task Greedy = {:.3f}s; Random = {:.3f}s;\\\n",
    "                \\n\".format(rt_dict['total'], rt_dict['lazyGreedy'], rt_dict['noUpdateGreedy'], rt_dict['taskGreedy'], rt_dict['random'])\n",
    "            outfile_bibsonomy.write(runtimeInfo)\n",
    "    \n",
    "    if write_flag:\n",
    "        outfile_bibsonomy.close()\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testBibsonomyDatasets(write_flag=True, algoList=['lazy_greedy', 'random', 'no_update_greedy', 'task_greedy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibsonomy_data_path = 'datasets/bibsonomy/'\n",
    "y=2015\n",
    "experts_file = bibsonomy_data_path + 'bibsonomy_experts_' + str(y) + '.txt'\n",
    "tasks_file = bibsonomy_data_path + 'bibsonomy_tasks_' + str(y) + '.txt'\n",
    "print(\"\\nBibsonomy Dataset: {}, {}\".format('bibsonomy_experts_' + str(y), 'bibsonomy_tasks_' + str(y)))\n",
    "\n",
    "bib_tasks, bib_experts = importBibsonomyData(experts_file, tasks_file)\n",
    "BibsonomyTest = TFP.TeamFormationProblem(bib_tasks, bib_experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDict, F_vals, workLoad_vals = BibsonomyTest.computeTaskAssigment(algorithms=['random', 'no_update_greedy', 'task_greedy'], lambdaVal=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot F_i for different Lambda for Lazy Greedy\n",
    "# plt.figure(figsize=(9,6))\n",
    "# for l_val in Fi_dict.keys():\n",
    "#     plt.plot(T_arr, Fi_dict[l_val], label='Lambda={:.3f}'.format(l_val))\n",
    "\n",
    "# # Plot the max values\n",
    "# plt.plot(TMaxArr, FMaxArr, '--*', label='Max F_i')\n",
    "\n",
    "# title_text = 'Lazy Greedy Performance by varying Lambda (Bibsonomy_2015)'\n",
    "# plt.title(title_text, fontsize=12)\n",
    "# plt.xlabel('Workload Threshold, T_i')\n",
    "# plt.ylabel('F_i')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_threshold_arr = [5,10,40,80,100,150,200]\n",
    "# rev_rt_arr, reg_rt_arr = [],[]\n",
    "# for thresh in max_threshold_arr:\n",
    "#     FreelancerTest = TFP.TeamFormationProblem(t[0:200], e[0:200], max_workload_threshold=thresh)\n",
    "#     rev_rt, reg_rt = FreelancerTest.compare_Methods()\n",
    "#     rev_rt_arr.append(rev_rt)\n",
    "#     reg_rt_arr.append(reg_rt)\n",
    "\n",
    "#Plot Runtimes\n",
    "# plt.figure(figsize=(9,6))\n",
    "# plt.plot(max_threshold_arr, rev_rt_arr, label='Reverse Threshold Runtime')\n",
    "# plt.plot(max_threshold_arr, reg_rt_arr, label='Regular Lazy Runtime')\n",
    "\n",
    "# title_text = 'Reverse Threshold vs. Regular Lazy runtimes'\n",
    "# plt.title(title_text, fontsize=11)\n",
    "# plt.xlabel('Max Threshold, T_i')\n",
    "# plt.ylabel('Runtime, s')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "#FreelancerTest.compute_reverseThreshold()\n",
    "#FreelancerTest.compareTest_Lazy_Stochastic_Assignments()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
