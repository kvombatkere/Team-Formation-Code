{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Team Formation framework with Freelancer Data\n",
    "## Balancing Task Coverage vs. Maximum Expert Load\n",
    "## Karan Vombatkere, Dec 2021\n",
    "\n",
    "#Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json, time\n",
    "import TeamFormationProblem as TFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary Testing\n",
    "task_list = [['s1', 's2', 's4', 's5'], ['s3', 's2'], ['s1', 's3', 's5'], ['s2', 's4'],['s1', 's4', 's5'], ['s3'], ['s1', 's5'], ['s2', 's4']]\n",
    "expert_list = [['s2', 's3'], ['s2', 's4'], ['s3'], ['s5', 's4']]\n",
    "\n",
    "teamFormationTest = TFP.TeamFormationProblem(task_list, expert_list, max_workload_threshold=6)\n",
    "#teamFormationTest.computeTaskAssigment(lazy_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdict = teamFormationTest.computeTaskAssigment(baselines=['task_greedy'], plot_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teamFormationTest.compareTest_Lazy_Stochastic_Assignments()\n",
    "#t,f, r = teamFormationTest.compute_reverseThreshold()\n",
    "#reverse_runtime, regular_runtime = teamFormationTest.compare_Methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freelancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Freelancer data\n",
    "#Freelancer from DropBox link: https://www.dropbox.com/sh/8zpsi1etvvvvj5k/AAD-J9ZQmSsbnSmEILBMD9uxa/datasets/real?dl=0&subfolder_nav_tracking=1\n",
    "#freelance_experts.csv and freelance_projects.csv\n",
    "\n",
    "def extract_skills(row):\n",
    "    skills = []\n",
    "    for i,val in enumerate(row):\n",
    "        if val == 1:\n",
    "            skills.append(str(i))\n",
    "    return skills            \n",
    "\n",
    "    \n",
    "def importFreelancerData(experts_filename='datasets/freelancer/freelancer_experts.csv', tasks_filename='datasets/freelancer/freelancer_projects.csv'):\n",
    "    #Extract tasks skills as list\n",
    "    freelance_tasks_df = pd.read_csv(tasks_filename, header=None)\n",
    "    freelance_tasks_df['Task_Skills'] = freelance_tasks_df.apply(lambda row: extract_skills(row), axis=1)\n",
    "    task_skills_list = freelance_tasks_df.Task_Skills.to_list()\n",
    "    \n",
    "    #Extract experts skills as list\n",
    "    freelance_experts_df = pd.read_csv(experts_filename, header=None)\n",
    "    freelance_experts_df['Expert_Skills'] = freelance_experts_df.apply(lambda row: extract_skills(row), axis=1)\n",
    "    expert_skills_list = freelance_experts_df.Expert_Skills.to_list()\n",
    "\n",
    "    print(\"Imported Freelancer dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,e = importFreelancerData()\n",
    "FreelancerTest = TFP.TeamFormationProblem(t, e, max_workload_threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtimes = FreelancerTest.computeTaskAssigment(baselines=['random','no_update_greedy'], plot_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import IMDB Data\n",
    "def importIMDBData(experts_filename, tasks_filename):\n",
    "    with open(experts_filename, 'r') as f:\n",
    "        expert_skills_list = json.loads(f.read())\n",
    "    \n",
    "    with open(tasks_filename, 'r') as f:\n",
    "        task_skills_list = json.loads(f.read())\n",
    "\n",
    "    print(\"Imported IMDB dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list, \n",
    "\n",
    "#Run algorithm on IMDB datasets\n",
    "def testIMDBDatasets():\n",
    "    imdb_data_path = 'datasets/imdb/'\n",
    "    movieYears = [2015, 2018, 2020]\n",
    "\n",
    "    runTimeStamp = str(time.strftime(\"%m-%d-%H:%M:%S\", time.localtime(time.time())))\n",
    "    imdb_outfilename = \"experiments/imdb_\" + runTimeStamp + \".txt\"\n",
    "    outfile_imdb = open(imdb_outfilename, \"a\")\n",
    "    outfile_imdb.write(\"IMDB dataset Team-Formation Algorithms: {}\\n\".format(runTimeStamp))\n",
    "\n",
    "    for y in movieYears:\n",
    "        experts_file = imdb_data_path + 'imdb_experts_' + str(y) + '.txt'\n",
    "        tasks_file = imdb_data_path + 'imdb_tasks_' + str(y) + '.txt'\n",
    "        print(\"IMDB Dataset: {}, {}\".format('imdb_experts_' + str(y), 'imdb_tasks_' + str(y)))\n",
    "\n",
    "        imdb_tasks, imdb_experts = importIMDBData(experts_file, tasks_file)\n",
    "        IMDBTest = TFP.TeamFormationProblem(imdb_tasks[0:100], imdb_experts[0:100])\n",
    "\n",
    "        rt_dict = IMDBTest.computeTaskAssigment(baselines=['random', 'no_update_greedy', 'task_greedy'], plot_flag=False)\n",
    "\n",
    "        #Write output to file\n",
    "        runInfo = \"\\nIMDB movieYear = {}, Experts = {}, Tasks = {}\".format(str(y), str(IMDBTest.n), str(IMDBTest.m))\n",
    "        outfile_imdb.write(runInfo)\n",
    "\n",
    "        runtimeInfo = \"\\nAlgorithm Runtimes: Total = {:.3f}s; Lazy Greedy = {:.3f}s; No-Update-Greedy = {:.3f}s; Task Greedy = {:.3f}s; Random = {:.3f}s;\\\n",
    "            \\n\".format(rt_dict['total'], rt_dict['lazyGreedy'], rt_dict['noUpdateGreedy'], rt_dict['taskGreedy'], rt_dict['random'])\n",
    "        outfile_imdb.write(runtimeInfo)\n",
    "        \n",
    "    outfile_imdb.close()\n",
    "\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testIMDBDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibsonomy Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Bibsonomy datasets\n",
    "def importBibsonomyData(experts_filename, tasks_filename):\n",
    "    with open(experts_filename, 'r') as f:\n",
    "        expert_skills_list = json.loads(f.read())\n",
    "    \n",
    "    with open(tasks_filename, 'r') as f:\n",
    "        task_skills_list = json.loads(f.read())\n",
    "\n",
    "    print(\"Imported Bibsonomy dataset. Num Experts={}, Num Tasks={}\".format(len(expert_skills_list),len(task_skills_list)))\n",
    "\n",
    "    return task_skills_list, expert_skills_list\n",
    "\n",
    "#Run algorithm on Bibsonomy datasets\n",
    "def testBibsonomyDatasets():\n",
    "    imdb_data_path = 'datasets/bibsonomy/'\n",
    "    movieYears = [2010, 2015, 2020]\n",
    "\n",
    "    runTimeStamp = str(time.strftime(\"%m-%d-%H:%M:%S\", time.localtime(time.time())))\n",
    "    bibs_outfilename = \"experiments/bibsonomy_\" + runTimeStamp + \".txt\"\n",
    "    outfile_bibsonomy = open(bibs_outfilename, \"a\")\n",
    "    outfile_bibsonomy.write(\"Bibsonomy dataset Team-Formation Algorithms: {}\\n\".format(runTimeStamp))\n",
    "\n",
    "    for y in movieYears:\n",
    "        experts_file = imdb_data_path + 'bibsonomy_experts_' + str(y) + '.txt'\n",
    "        tasks_file = imdb_data_path + 'bibsonomy_tasks_' + str(y) + '.txt'\n",
    "        print(\"\\nBibsonomy Dataset: {}, {}\".format('bibsonomy_experts_' + str(y), 'bibsonomy_tasks_' + str(y)))\n",
    "\n",
    "        bib_tasks, bib_experts = importBibsonomyData(experts_file, tasks_file)\n",
    "        BibsonomyTest = TFP.TeamFormationProblem(bib_tasks[0:100], bib_experts[0:200])\n",
    "\n",
    "        rt_dict = BibsonomyTest.computeTaskAssigment(baselines=['random', 'no_update_greedy', 'task_greedy'], plot_flag=False)\n",
    "\n",
    "        #Write output to file\n",
    "        runInfo = \"\\nBibsonomy paperYear = {}, Experts = {}, Tasks = {}\".format(str(y), str(BibsonomyTest.n), str(BibsonomyTest.m))\n",
    "        outfile_bibsonomy.write(runInfo)\n",
    "\n",
    "        runtimeInfo = \"\\nAlgorithm Runtimes: Total = {:.3f}s; Lazy Greedy = {:.3f}s; No-Update-Greedy = {:.3f}s; Task Greedy = {:.3f}s; Random = {:.3f}s;\\\n",
    "            \\n\".format(rt_dict['total'], rt_dict['lazyGreedy'], rt_dict['noUpdateGreedy'], rt_dict['taskGreedy'], rt_dict['random'])\n",
    "        outfile_bibsonomy.write(runtimeInfo)\n",
    "\n",
    "    outfile_bibsonomy.close()\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testBibsonomyDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_threshold_arr = [5,10,40,80,100,150,200]\n",
    "# rev_rt_arr, reg_rt_arr = [],[]\n",
    "# for thresh in max_threshold_arr:\n",
    "#     FreelancerTest = TFP.TeamFormationProblem(t[0:200], e[0:200], max_workload_threshold=thresh)\n",
    "#     rev_rt, reg_rt = FreelancerTest.compare_Methods()\n",
    "#     rev_rt_arr.append(rev_rt)\n",
    "#     reg_rt_arr.append(reg_rt)\n",
    "\n",
    "#Plot Runtimes\n",
    "# plt.figure(figsize=(9,6))\n",
    "# plt.plot(max_threshold_arr, rev_rt_arr, label='Reverse Threshold Runtime')\n",
    "# plt.plot(max_threshold_arr, reg_rt_arr, label='Regular Lazy Runtime')\n",
    "\n",
    "# title_text = 'Reverse Threshold vs. Regular Lazy runtimes'\n",
    "# plt.title(title_text, fontsize=11)\n",
    "# plt.xlabel('Max Threshold, T_i')\n",
    "# plt.ylabel('Runtime, s')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "#FreelancerTest.compute_reverseThreshold()\n",
    "#FreelancerTest.compareTest_Lazy_Stochastic_Assignments()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
